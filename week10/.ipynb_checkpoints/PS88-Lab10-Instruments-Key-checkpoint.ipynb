{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f98573",
   "metadata": {},
   "source": [
    "# PS 88 Lab 10: Instruments and Lotteries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d9e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import statsmodels.api as sm \n",
    "import statsmodels.formula.api as smf \n",
    "from itertools import combinations \n",
    "import seaborn as sns\n",
    "from linearmodels.iv import IV2SLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d8e948",
   "metadata": {},
   "source": [
    "## Part 1. Building on a Class Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c246c28b",
   "metadata": {},
   "source": [
    "Let's do a simulation of the example I gave in class, where I flip a coin for each student in a class, and for those who get heads I give them `amount=30` dollars if they attend the next lecture. Imagine a researcher does not know the exact amount I gave, and tries to figure it out by comparing how much cash everyone has in their wallet afterwards.\n",
    "\n",
    "First let's define the amount I propose to give, and randomly generate the `baseline` amount of money-in-wallet held by a large class (2000 students). Assume this is uniformly distrubuted between 0 and 100. We store the result of the coinflip with the variable `ittreat` (\"intention to treat\"), equal to 1 for those who I will give `amount` to if they show up to class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bda3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(78)\n",
    "amount = 30\n",
    "nstudent = 2000\n",
    "baseline = 100*np.random.rand(nstudent)\n",
    "ittreat = np.where(np.random.rand(nstudent) > .5,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849aeb94",
   "metadata": {},
   "source": [
    "Let's make an extreme assumption that the only people who show up to class are those with less than 50 dollars in their wallet (maybe they think they have better things to do). \n",
    "\n",
    "Let `showup` be equal to 1 for those who show up to lecture and 0 for those who do not. Those who get the money are those with `showup=1` and `ittreat=1`. So, we can compute the actual treatment (receiving `amount`) by multiplying `showup` times `ittreat`. The realized money-in-wallet is then equal to `baseline + amount` for those who get treated, and  `baseline` otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6e0790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "showup = np.where(baseline < 50,1,0)\n",
    "treat = showup*ittreat\n",
    "realized = np.where(treat, baseline + amount, baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17456759",
   "metadata": {},
   "source": [
    "Now let's suppose the resarcher has access to a dataset which tells them (1) the student coinflip (`ittreat`, or the \"instrument\"), (2) whether they get treated, and (3) their realized money-in-wallet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "137ee77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument</th>\n",
       "      <th>treat</th>\n",
       "      <th>wallet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.818123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68.096301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79.869607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.010859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.529725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.394192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.562628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.730331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97.876486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      instrument  treat     wallet\n",
       "0              1      1  34.818123\n",
       "1              1      0  68.096301\n",
       "2              1      0  79.869607\n",
       "3              0      0  80.010859\n",
       "4              0      0  96.529725\n",
       "...          ...    ...        ...\n",
       "1995           0      0  59.792500\n",
       "1996           0      0  96.394192\n",
       "1997           0      0   1.562628\n",
       "1998           1      0  50.730331\n",
       "1999           0      0  97.876486\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = pd.DataFrame(data={'instrument': ittreat, \n",
    "                             'treat': treat, \n",
    "                             'wallet': realized})\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0caa77",
   "metadata": {},
   "source": [
    "We can the compute the \"first stage\" as the difference in receiving the treatment among those who got heads on their coinflip (`obs['instrument']==1`) vs not (`obs['instrument']==0`).\n",
    "\n",
    "We can also compute the \"reduced form\" which is the difference in outcome (`wallet`) between those who got heads on their coinflip vs not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35e26013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4925373134328358 15.155059201837467\n"
     ]
    }
   ],
   "source": [
    "# First stage\n",
    "phi = (np.mean(obs.loc[obs['instrument']==1, 'treat']) - \n",
    "       np.mean(obs.loc[obs['instrument']==0, 'treat']))\n",
    "# Reduced form\n",
    "rho = (np.mean(obs.loc[obs['instrument']==1, 'wallet']) - \n",
    "       np.mean(obs.loc[obs['instrument']==0, 'wallet']))\n",
    "\n",
    "print(phi,rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c25cc",
   "metadata": {},
   "source": [
    "**Question 1.1. Use the formula for the Local Average Treatment Effect to recover the causal effect of the treatment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d11af5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.769362621912435"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho/phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1627fc",
   "metadata": {},
   "source": [
    "In lecture I said we can assume that the baseline money of those with a heads coin flip will be pretty similar to those who get a tails coin flip. Let's check this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e2bd70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37893979885256357"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(baseline[ittreat == 1]) - np.mean(baseline[ittreat == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4698f",
   "metadata": {},
   "source": [
    "**Question 1.2. Now compute a \"naive\" difference of means between the amount of money-in-wallet among those who received the treatment versus not.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d23ed22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.4662312858614897"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom = (np.mean(obs.loc[obs['treat']==1, 'wallet']) - \n",
    "       np.mean(obs.loc[obs['treat']==0, 'wallet']))\n",
    "dom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6910df81",
   "metadata": {},
   "source": [
    "**Question 1.3. Among your answers to 1.1 and 1.2, one of them should be close to the real `amount` given in this simulation. Why is this answer a good estimate while the other is not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60ce1ec",
   "metadata": {},
   "source": [
    "The LATE estiamate from 1.1 is very close to the true treatment effect of 30, while the naive difference is -3.5. The naive difference gives a very incorrect answer because to receive the treatment one needs to show up to class, and we assumed that people with less money in their wallet are more likely to show up to class. The LATE estimate, on the other hand, has no selection bias since the intention to treat is random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ea0b8",
   "metadata": {},
   "source": [
    "Now let's consider an alternative version of the simulation where only those who have more money-in-pocket at the baseline show up to class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03aab250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument</th>\n",
       "      <th>treat</th>\n",
       "      <th>wallet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.818123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98.096301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109.869607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.010859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.529725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.394192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.562628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80.730331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97.876486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      instrument  treat      wallet\n",
       "0              1      0    4.818123\n",
       "1              1      1   98.096301\n",
       "2              1      1  109.869607\n",
       "3              0      0   80.010859\n",
       "4              0      0   96.529725\n",
       "...          ...    ...         ...\n",
       "1995           0      0   59.792500\n",
       "1996           0      0   96.394192\n",
       "1997           0      0    1.562628\n",
       "1998           1      1   80.730331\n",
       "1999           0      0   97.876486\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showup2 = baseline > 50\n",
    "treat2 = showup2*ittreat\n",
    "realized2 = np.where(treat2, baseline + amount, baseline)\n",
    "obs2 = pd.DataFrame(data={'instrument': ittreat, \n",
    "                             'treat': treat2, \n",
    "                             'wallet': realized2})\n",
    "obs2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dd6172",
   "metadata": {},
   "source": [
    "**Question 1.4. Compute the first stage, reduced form, and local average treatment effect, and \"naive\" difference of means for these data. Compare your answers to what you got in 1.1-1.3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94bd716f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.746734309503246"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First stage\n",
    "phi2 = (np.mean(obs2.loc[obs2['instrument']==1, 'treat']) - \n",
    "       np.mean(obs2.loc[obs2['instrument']==0, 'treat']))\n",
    "# Reduced form\n",
    "rho2 = (np.mean(obs2.loc[obs2['instrument']==1, 'wallet']) - \n",
    "       np.mean(obs2.loc[obs2['instrument']==0, 'wallet']))\n",
    "rho2/phi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bd2cdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.30758781095169"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom2 = (np.mean(obs2.loc[obs2['treat']==1, 'wallet']) - \n",
    "       np.mean(obs2.loc[obs2['treat']==0, 'wallet']))\n",
    "dom2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2a92d",
   "metadata": {},
   "source": [
    "The LATE again gives an answer very close to the truth. The naive difference of means is now much higher than the truth because in this simulation people with more money are more likely to show up to class and receive the treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c090ddb2",
   "metadata": {},
   "source": [
    "## Part 2. Health Insurance, Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc36564",
   "metadata": {},
   "source": [
    "Section 1.2 of Mastering Metrics contains a discussion of the \"Oregon Health Experiment (OHP)\", where Oregon decided to expand access to Medicaid (health insurance for those with low incomes) by lottery. 75,000 people were entered in the lottery, and 30,000 won, meaning they were invited to apply to the program, but still had to do so on time and meet other eligibility requirements. In the end, 40% of the winners received coverage. The lottery losers were also sometimes able to get access to coverage as well, and 14% did so.\n",
    "\n",
    "Here are some differences in average outcomes for lottery winners and losers (from Table 1.5; some of these come from a sample of just the Portland area but we can set this difference aside):\n",
    "- Winners had an average of 0.1 more visits to an emergency room\n",
    "- Winners were 3.9% more likely to say their \"health is good\"\n",
    "- Winners had a higher average score of 0.29 on a 100 point scale for physical health\n",
    "- Winners were 3% less likely to have medical debt\n",
    "\n",
    "**Question 2.1. Compute the local average treatment effect of *getting Medicaid* for these four outcomes. Hint: use the difference in receiving Medicaid between lottery winners and losers to compute the \"first stage\" (`phi`), and then use the four differences in winners/losers reported above as the the \"reduced form\" (you can call these `rho_er`, `rho_good`, etc.), and use the `rho/phi` formula to compute the LATE for each outcome.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a30975cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38461538461538464, 0.15, 1.1153846153846152, 0.11538461538461538)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi = .4 - .14\n",
    "rho_er = .1\n",
    "rho_good = .039\n",
    "rho_scale=.29\n",
    "rho_debt=.03\n",
    "rho_er/phi, rho_good/phi, rho_scale/phi, rho_debt/phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf2043",
   "metadata": {},
   "source": [
    "One reason this study is so prominent is that it speaks to a huge debate in the United States about whether providing government insurance (like Medicaid) to all Americans would improve health outcomes/lower health care spending. \n",
    "\n",
    "**Question 2.2. Identify one of the results from part 2.1 that supports the argument that the government *should* provide more insurance, and one result that supports the argument that the government *should not* provide more insurance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b18cbb",
   "metadata": {},
   "source": [
    "On the \"good news\" front, winners were over 10% less likely to have medical debt, which is a huge financial relief form many. On the bad news front, getting insurance only increased physical health by about 1 point on a 100 point scale, which is not a big increase for something as expensive as health insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5c49f8",
   "metadata": {},
   "source": [
    "## Part 3. A Political Lottery/When to *Not* Use 2SLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3230c89",
   "metadata": {},
   "source": [
    "A prominent example of a \"real world\" lottery in the political realm was the Vietnam draft lottery in 1969. You can read more about it <a href=\"https://en.wikipedia.org/wiki/Draft_lottery_(1969)\">here</a>.\n",
    "\n",
    "For our purposes, the key thing to know is that the draft lottery primarily affected men who (1) were born between 1944 and 1950, (2) had not yet enlisted in the military, and (3) had previously received a deferral due to being in college. The lottery itself gave a random \"ranking\" to all dates of birth, i.e., each DOB was given a lottery number from 1 to 366. (See what your draft number would have been <a href='http://history.hanover.edu/pictures2/1969-1202-madcour-p2-lottery.jpg'>here</a>!) Those who were born on a date with a lower number were more likely to be drafted, though whether this actually happened depended on several other factors. For example, some would have been ruled ineligible for service for medical reasons, or lived in places that already filled quotas for the number of men to enlist.\n",
    "\n",
    "In a widely cited <a href=\"https://www.jstor.org/stable/41495063?seq=1#metadata_info_tab_contents\">paper</a>, Berkeley's own Laura Stoker (and Robert Erikson) used a survey of men who were born in 1948 to see what the effect of the draft number was on attitudes towards the war and other political attitudes.\n",
    "\n",
    "Let's pull up their replication data. (The `convert_categoricals=False` argument prevents an error related to some variables we won't work with.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8f15215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v5</th>\n",
       "      <th>viet3</th>\n",
       "      <th>vietx</th>\n",
       "      <th>z65</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>...</th>\n",
       "      <th>atheist</th>\n",
       "      <th>communist</th>\n",
       "      <th>civ265ynew</th>\n",
       "      <th>un</th>\n",
       "      <th>nummisz65</th>\n",
       "      <th>tempun</th>\n",
       "      <th>temppray</th>\n",
       "      <th>tempintg</th>\n",
       "      <th>tempciv</th>\n",
       "      <th>z65new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.125</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1589</td>\n",
       "      <td>9651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1513</td>\n",
       "      <td>9271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>443</td>\n",
       "      <td>3651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1261</td>\n",
       "      <td>7751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1597</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>510</td>\n",
       "      <td>4051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>642</td>\n",
       "      <td>4871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.250</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1126</td>\n",
       "      <td>7151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1255</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.125</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1434</td>\n",
       "      <td>8871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>248</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.500</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>663</td>\n",
       "      <td>4971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>299</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1526</td>\n",
       "      <td>9271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1348 rows Ã— 1272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v5  viet3  vietx    z65    v1  v2  v3  v4    v6    v7  ...  atheist  \\\n",
       "0     1593    1.0   0.50  0.125  7779   2   1   1  1589  9651  ...      0.0   \n",
       "1       88    1.0   0.50    NaN  7779   2   1   1  1513  9271  ...      0.0   \n",
       "2     1015    0.0   0.50  0.500  7779   2   1   1   443  3651  ...      0.0   \n",
       "3     1408    0.0   0.00    NaN  7779   2   1   1  1261  7751  ...      0.0   \n",
       "4     1597    0.5   0.75  0.250  7779   2   1   1   510  4051  ...      0.0   \n",
       "...    ...    ...    ...    ...   ...  ..  ..  ..   ...   ...  ...      ...   \n",
       "1343    77    1.0   0.50  0.500  7779   2   1   1   642  4871  ...      0.0   \n",
       "1344  1004    0.0   0.25  0.250  7779   2   1   1  1126  7151  ...      0.0   \n",
       "1345  1255    0.5   0.50  0.125  7779   2   1   1  1434  8871  ...      0.0   \n",
       "1346   248    0.5   0.75  0.500  7779   2   1   1   663  4971  ...      0.0   \n",
       "1347   299    0.5   0.75  0.250  7779   2   1   1  1526  9271  ...      0.0   \n",
       "\n",
       "      communist  civ265ynew   un  nummisz65  tempun  temppray  tempintg  \\\n",
       "0           1.0         0.5  0.0        4.0     0.0       0.0       0.0   \n",
       "1           1.0         0.5  NaN        2.0     0.0       1.0       0.0   \n",
       "2           0.0         0.0  0.0        4.0     0.0       1.0       1.0   \n",
       "3           1.0         0.5  NaN        2.0     0.0       0.0       0.0   \n",
       "4           0.0         0.0  0.0        4.0     0.0       1.0       0.0   \n",
       "...         ...         ...  ...        ...     ...       ...       ...   \n",
       "1343        1.0         0.5  0.0        4.0     0.0       1.0       0.5   \n",
       "1344        1.0         0.5  0.0        4.0     0.0       0.0       0.5   \n",
       "1345        0.0         0.0  0.0        4.0     0.0       0.5       0.0   \n",
       "1346        0.0         0.0  0.0        4.0     0.0       1.0       1.0   \n",
       "1347        0.0         0.0  0.0        4.0     0.0       1.0       0.0   \n",
       "\n",
       "      tempciv  z65new  \n",
       "0         0.5   0.125  \n",
       "1         0.5   0.750  \n",
       "2         0.0   0.500  \n",
       "3         0.5   0.250  \n",
       "4         0.0   0.250  \n",
       "...       ...     ...  \n",
       "1343      0.5   0.500  \n",
       "1344      0.5   0.250  \n",
       "1345      0.0   0.125  \n",
       "1346      0.0   0.500  \n",
       "1347      0.0   0.250  \n",
       "\n",
       "[1348 rows x 1272 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viet = pd.read_stata(\"es_rep.dta\", convert_categoricals=False)\n",
    "viet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad43607",
   "metadata": {},
   "source": [
    "Recall we are primarily intested in respondents who had attended college and not yet served in the military. We can identify this subset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5ae39a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v5</th>\n",
       "      <th>viet3</th>\n",
       "      <th>vietx</th>\n",
       "      <th>z65</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>...</th>\n",
       "      <th>atheist</th>\n",
       "      <th>communist</th>\n",
       "      <th>civ265ynew</th>\n",
       "      <th>un</th>\n",
       "      <th>nummisz65</th>\n",
       "      <th>tempun</th>\n",
       "      <th>temppray</th>\n",
       "      <th>tempintg</th>\n",
       "      <th>tempciv</th>\n",
       "      <th>z65new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>833</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.375</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>335</td>\n",
       "      <td>2731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>956</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.375</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>683</td>\n",
       "      <td>5071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>259</td>\n",
       "      <td>2331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.750</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>747</td>\n",
       "      <td>5372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>483</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>883</td>\n",
       "      <td>6071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.375</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>891</td>\n",
       "      <td>6071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>438</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.250</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>558</td>\n",
       "      <td>4351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>486</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.375</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>886</td>\n",
       "      <td>6071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1255</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.125</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1434</td>\n",
       "      <td>8871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>248</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.500</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>663</td>\n",
       "      <td>4971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows Ã— 1272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v5  viet3  vietx    z65    v1  v2  v3  v4    v6    v7  ...  atheist  \\\n",
       "676    833    0.5   0.25  0.375  7779   2   1   1   335  2731  ...      0.0   \n",
       "679    956    0.5   0.75  0.375  7779   2   1   1   683  5071  ...      0.0   \n",
       "683    914    0.0   0.00  0.250  7779   2   1   1   259  2331  ...      0.0   \n",
       "686    586    1.0   0.50  0.750  7779   2   1   1   747  5372  ...      0.0   \n",
       "687    483    0.5   0.25    NaN  7779   2   1   1   883  6071  ...      0.0   \n",
       "...    ...    ...    ...    ...   ...  ..  ..  ..   ...   ...  ...      ...   \n",
       "1333   596    0.0   0.50  0.375  7779   2   1   1   891  6071  ...      0.0   \n",
       "1334   438    0.5   0.25  0.250  7779   2   1   1   558  4351  ...      0.0   \n",
       "1339   486    0.5   0.75  0.375  7779   2   1   1   886  6071  ...      0.0   \n",
       "1345  1255    0.5   0.50  0.125  7779   2   1   1  1434  8871  ...      0.0   \n",
       "1346   248    0.5   0.75  0.500  7779   2   1   1   663  4971  ...      0.0   \n",
       "\n",
       "      communist  civ265ynew   un  nummisz65  tempun  temppray  tempintg  \\\n",
       "676         1.0         0.5  0.0        4.0     0.0       1.0       0.0   \n",
       "679         0.0         0.0  0.0        4.0     0.0       1.0       0.5   \n",
       "683         0.0         0.0  0.0        4.0     0.0       1.0       0.0   \n",
       "686         0.0         0.0  1.0        4.0     1.0       1.0       1.0   \n",
       "687         1.0         0.5  0.0        3.0     0.0       0.0       0.0   \n",
       "...         ...         ...  ...        ...     ...       ...       ...   \n",
       "1333        1.0         0.5  0.0        4.0     0.0       0.0       1.0   \n",
       "1334        0.0         0.0  0.0        4.0     0.0       1.0       0.0   \n",
       "1339        1.0         0.5  0.0        4.0     0.0       1.0       0.0   \n",
       "1345        0.0         0.0  0.0        4.0     0.0       0.5       0.0   \n",
       "1346        0.0         0.0  0.0        4.0     0.0       1.0       1.0   \n",
       "\n",
       "      tempciv    z65new  \n",
       "676       0.5  0.375000  \n",
       "679       0.0  0.375000  \n",
       "683       0.0  0.250000  \n",
       "686       0.0  0.750000  \n",
       "687       0.5  0.166667  \n",
       "...       ...       ...  \n",
       "1333      0.5  0.375000  \n",
       "1334      0.0  0.250000  \n",
       "1339      0.5  0.375000  \n",
       "1345      0.0  0.125000  \n",
       "1346      0.0  0.500000  \n",
       "\n",
       "[261 rows x 1272 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnomil = viet[(viet['cprep']==1) & (viet['milpre69'] == 0)]\n",
    "colnomil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c7f1d",
   "metadata": {},
   "source": [
    "We are down to a relevant sample of 261, which isn't huge, but enough to work with.\n",
    "\n",
    "The outcome variable we will consider is `vietx`, an index of pro-war attitudes which ranges from 0 (most anti-war) to 1 (most pro-war). It can take on values 0, .25,  .5, ,75, or 1.\n",
    "\n",
    "Let's look at a histogram of this (setting bins=5 to make it look nicer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e8796d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnomil['vietx'].hist(bins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc6c60c",
   "metadata": {},
   "source": [
    "**Question 3.1 Make a similar histogram using  the full sample (i.e., the `viet` dataframe rather than `colnomil`. How do the war attitudes differ among the full sample vs the college-attenders who did not  yet enlist?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ab5b8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUiklEQVR4nO3df4xdd5nf8fdnTQipTfOjSUbe2Fu7rWnXwSW7mWZRaasxWTVDWtVB2lSmbXCWVKZqWLGqpa7DH4UVskSlzbJqILtrSGS3uEwtftQuP7bKeneaoiV4YxriOCHFJWlwHNmFhMCkKNWYp3/MQVzsGc+duXdmcs99v6TRved7zvfe55nr+cyZ43vPSVUhSWqXn1vpAiRJ/We4S1ILGe6S1EKGuyS1kOEuSS30upUuAODqq6+uDRs2LHr+K6+8wurVq/tX0GvcsPUL9jws7Hlhjh079t2quma2da+JcN+wYQOPPvrooudPTk4yNjbWv4Je44atX7DnYWHPC5Pkf8+1zsMyktRChrsktZDhLkktZLhLUgsZ7pLUQoa7JLWQ4S5JLWS4S1ILGe6S1EKviU+o9ur48y9z5+4vrnQZy2bf+HB9PFvSwrnnLkktZLhLUgsZ7pLUQoa7JLWQ4S5JLWS4S1ILdR3uSVYl+R9JvtAsX5XkoSTfam6v7Nj2niQnkzyd5JalKFySNLeF7Lm/H3iqY3k3cKSqNgFHmmWSbAa2A9cD48D9SVb1p1xJUje6Cvck64B/AHyyY3gbsL+5vx+4rWN8oqperapngJPATX2pVpLUlW4/ofp7wL8G3tgxNlJVLwBU1QtJrm3GrwMe6djuVDP2M5LsBHYCjIyMMDk5uaDCO41cBru2TC96/qCZmprq6fs1iOx5ONhz/8wb7kn+IXC2qo4lGeviMTPLWF0wULUX2AswOjpavVwU974Dh7j3eCvOpNCVfeOrvYjwELDn4bBUPXeTiG8D/lGSW4E3AH8xyaeAM0nWNnvta4GzzfangPUd89cBp/tZtCTp4uY95l5V91TVuqrawMx/lP5JVf0z4DCwo9lsB3CouX8Y2J7k0iQbgU3A0b5XLkmaUy/HMj4CHExyF/AccDtAVZ1IchB4EpgG7q6qcz1XKknq2oLCvaomgcnm/veAm+fYbg+wp8faJEmL5CdUJamFDHdJaiHDXZJayHCXpBYy3CWphQx3SWohw12SWshwl6QWMtwlqYUMd0lqIcNdklrIcJekFjLcJamFDHdJaiHDXZJaaN5wT/KGJEeTfCPJiSS/3Yx/KMnzSR5rvm7tmHNPkpNJnk5yy1I2IEm6UDcX63gVeHtVTSW5BPhKki836z5aVb/TuXGSzcxcju964OeBP07yJq/GJEnLp5trqFZVTTWLlzRfdZEp24CJqnq1qp4BTgI39VypJKlrXR1zT7IqyWPAWeChqvpas+p9SR5P8mCSK5ux64DvdEw/1YxJkpZJqi62E37exskVwOeB3wD+D/BdZvbiPwysrar3JPk48NWq+lQz5wHgS1X12fMeayewE2BkZOTGiYmJRTdx9sWXOfOjRU8fOBsvX8WaNWtWuoxlNTU1Zc9DwJ4XZuvWrceqanS2dQu9QPb3k0wC453H2pN8AvhCs3gKWN8xbR1wepbH2gvsBRgdHa2xsbGFlPIz7jtwiHuPL6iVgbZvfDW9fL8G0eTkpD0PAXvun27eLXNNs8dOksuAXwW+mWRtx2bvBJ5o7h8Gtie5NMlGYBNwtK9VS5Iuqpvd3bXA/iSrmPllcLCqvpDkPyS5gZnDMs8C7wWoqhNJDgJPAtPA3b5TRpKW17zhXlWPA780y/gdF5mzB9jTW2mSpMXyE6qS1EKGuyS1kOEuSS1kuEtSCxnuktRChrsktZDhLkktNDyf2ddAO/78y9y5+4srXcay2je+eqVL0ABzz12SWshwl6QWMtwlqYUMd0lqIcNdklrIcJekFjLcJamFDHdJaqFuLrP3hiRHk3wjyYkkv92MX5XkoSTfam6v7JhzT5KTSZ5OcstSNiBJulA3e+6vAm+vqrcANwDjSd4K7AaOVNUm4EizTJLNwHbgemAcuL+5RJ8kaZnMG+41Y6pZvKT5KmAbsL8Z3w/c1tzfBkxU1atV9QxwEripn0VLki6uq3PLNHvex4C/Bny8qr6WZKSqXgCoqheSXNtsfh3wSMf0U83Y+Y+5E9gJMDIywuTk5KKbGLkMdm2ZXvT8QTM1NdXT92sQDdtrDMP5Ottz/3QV7lV1DrghyRXA55O8+SKbZ7aHmOUx9wJ7AUZHR2tsbKybUmZ134FD3Ht8eM6Btm98Nb18vwbRsL3GMJyv8+TkpD33yYLeLVNV3wcmmTmWfibJWoDm9myz2Slgfce0dcDpXguVJHWvm3fLXNPssZPkMuBXgW8Ch4EdzWY7gEPN/cPA9iSXJtkIbAKO9rluSdJFdPN37lpgf3Pc/eeAg1X1hSRfBQ4muQt4DrgdoKpOJDkIPAlMA3c3h3UkSctk3nCvqseBX5pl/HvAzXPM2QPs6bk6SdKi+AlVSWohw12SWshwl6QWMtwlqYUMd0lqIcNdklrIcJekFjLcJamFDHdJaiHDXZJayHCXpBYy3CWphQx3SWohw12SWshwl6QWMtwlqYW6ucze+iR/muSpJCeSvL8Z/1CS55M81nzd2jHnniQnkzyd5JalbECSdKFuLrM3Deyqqq8neSNwLMlDzbqPVtXvdG6cZDOwHbge+Hngj5O8yUvtSdLymXfPvapeqKqvN/d/CDwFXHeRKduAiap6taqeAU4CN/WjWElSd1JV3W+cbAAeBt4M/CvgTuAHwKPM7N2/lORjwCNV9almzgPAl6vqM+c91k5gJ8DIyMiNExMTi27i7Isvc+ZHi54+cDZevoo1a9asdBnLatheYxjO13lqasqeF2Dr1q3Hqmp0tnXdHJYBIMka4LPAb1bVD5L8PvBhoJrbe4H3AJll+gW/QapqL7AXYHR0tMbGxrot5QL3HTjEvce7bmXg7RtfTS/fr0E0bK8xDOfrPDk5ac990tW7ZZJcwkywH6iqzwFU1ZmqOldVPwY+wU8PvZwC1ndMXwec7l/JkqT5dPNumQAPAE9V1e92jK/t2OydwBPN/cPA9iSXJtkIbAKO9q9kSdJ8uvk7923AHcDxJI81Yx8A3pXkBmYOuTwLvBegqk4kOQg8ycw7be72nTKStLzmDfeq+gqzH0f/0kXm7AH29FCXJKkHfkJVklrIcJekFjLcJamFDHdJaiHDXZJayHCXpBYy3CWphQx3SWohw12SWshwl6QWMtwlqYUMd0lqoeG6+kFLHH/+Ze7c/cWVLmNZ7dqy0hVIg8U9d0lqIcNdklqomysxrU/yp0meSnIiyfub8auSPJTkW83tlR1z7klyMsnTSW5ZygYkSRfqZs99GthVVb8IvBW4O8lmYDdwpKo2AUeaZZp124HrgXHg/iSrlqJ4SdLs5g33qnqhqr7e3P8h8BRwHbAN2N9sth+4rbm/DZioqler6hngJD+9eLYkaRmkqrrfONkAPAy8GXiuqq7oWPdSVV2Z5GPAI1X1qWb8AeDLVfWZ8x5rJ7ATYGRk5MaJiYlFN3H2xZc586NFTx84I5cxVP3CcPa88fJVrFmzZqXLWFZTU1P2vABbt249VlWjs63r+q2QSdYAnwV+s6p+kMx2WdWZTWcZu+A3SFXtBfYCjI6O1tjYWLelXOC+A4e49/jwvKtz15bpoeoXhrPnfeOr6eXnYhBNTk7ac5909W6ZJJcwE+wHqupzzfCZJGub9WuBs834KWB9x/R1wOn+lCtJ6kY375YJ8ADwVFX9bseqw8CO5v4O4FDH+PYklybZCGwCjvavZEnSfLr5O/dtwB3A8SSPNWMfAD4CHExyF/AccDtAVZ1IchB4kpl32txdVef6XbgkaW7zhntVfYXZj6MD3DzHnD3Anh7qkjSEhvHUGvvGVy/J4/oJVUlqIcNdklrIcJekFjLcJamFDHdJaiHDXZJayHCXpBYy3CWphQx3SWohw12SWshwl6QWMtwlqYUMd0lqIcNdklrIcJekFjLcJamFurnM3oNJziZ5omPsQ0meT/JY83Vrx7p7kpxM8nSSW5aqcEnS3LrZc98HjM8y/tGquqH5+hJAks3AduD6Zs79SVb1q1hJUnfmDfeqehh4scvH2wZMVNWrVfUMcBK4qYf6JEmL0M0FsufyviTvBh4FdlXVS8B1wCMd25xqxi6QZCewE2BkZITJyclFFzJyGezaMr3o+YNm2PqF4ex5amqqp5+LQeTr3D+LDfffBz4MVHN7L/AeZr+Qds32AFW1F9gLMDo6WmNjY4ssBe47cIh7j/fye2qw7NoyPVT9wnD2vG98Nb38XAyiYftZhqV7nRf1bpmqOlNV56rqx8An+Omhl1PA+o5N1wGneytRkrRQiwr3JGs7Ft8J/OSdNIeB7UkuTbIR2AQc7a1ESdJCzfv3T5JPA2PA1UlOAR8ExpLcwMwhl2eB9wJU1YkkB4EngWng7qo6tySVS5LmNG+4V9W7Zhl+4CLb7wH29FKUJKk3fkJVklrIcJekFjLcJamFDHdJaiHDXZJayHCXpBYy3CWphYbrJA7SADn+/MvcufuLK13Gstq1ZaUraA/33CWphQx3SWohw12SWshwl6QWMtwlqYUMd0lqIcNdklpo3nBP8mCSs0me6Bi7KslDSb7V3F7Zse6eJCeTPJ3klqUqXJI0t2723PcB4+eN7QaOVNUm4EizTJLNwHbg+mbO/UlW9a1aSVJX5g33qnoYePG84W3A/ub+fuC2jvGJqnq1qp4BTvLTi2dLkpbJYo+5j1TVCwDN7bXN+HXAdzq2O9WMSZKWUb/PLZNZxmrWDZOdwE6AkZERJicnF/2kI5fBri3Ti54/aIatX7DnYTGMPU9NTfWUf3NZbLifSbK2ql5IshY424yfAtZ3bLcOOD3bA1TVXmAvwOjoaI2NjS2yFLjvwCHuPT4850DbtWV6qPoFex4Ww9jzvvHV9JJ/c1nsYZnDwI7m/g7gUMf49iSXJtkIbAKO9laiJGmh5v0VmeTTwBhwdZJTwAeBjwAHk9wFPAfcDlBVJ5IcBJ4EpoG7q+rcEtUuSZrDvOFeVe+aY9XNc2y/B9jTS1GSpN74CVVJaiHDXZJayHCXpBYy3CWphQx3SWohw12SWshwl6QWMtwlqYUMd0lqIcNdklrIcJekFjLcJamFDHdJaiHDXZJayHCXpBYy3CWphXq6WGGSZ4EfAueA6aoaTXIV8J+ADcCzwD+uqpd6K1OStBD92HPfWlU3VNVos7wbOFJVm4AjzbIkaRktxWGZbcD+5v5+4LYleA5J0kWkqhY/OXkGeAko4A+ram+S71fVFR3bvFRVV84ydyewE2BkZOTGiYmJRddx9sWXOfOjRU8fOCOXMVT9gj0Pi2HseePlq1izZs2i5m7duvVYx1GTn9HTMXfgbVV1Osm1wENJvtntxKraC+wFGB0drbGxsUUXcd+BQ9x7vNdWBseuLdND1S/Y87AYxp73ja+ml/ybS0+HZarqdHN7Fvg8cBNwJslagOb2bK9FSpIWZtHhnmR1kjf+5D7w94EngMPAjmazHcChXouUJC1ML3//jACfT/KTx/mPVfVHSf4cOJjkLuA54Pbey5QkLcSiw72qvg28ZZbx7wE391KUJKk3fkJVklrIcJekFjLcJamFDHdJaiHDXZJayHCXpBYy3CWphQx3SWohw12SWshwl6QWMtwlqYUMd0lqIcNdklrIcJekFjLcJamFDHdJaqElC/ck40meTnIyye6leh5J0oWWJNyTrAI+DrwD2Ay8K8nmpXguSdKFlmrP/SbgZFV9u6r+HzABbFui55IknSdV1f8HTX4NGK+qf94s3wH8SlW9r2ObncDOZvGvA0/38JRXA9/tYf6gGbZ+wZ6HhT0vzF+uqmtmW7HoC2TPI7OM/cxvkaraC+zty5Mlj1bVaD8eaxAMW79gz8PCnvtnqQ7LnALWdyyvA04v0XNJks6zVOH+58CmJBuTvB7YDhxeoueSJJ1nSQ7LVNV0kvcB/xVYBTxYVSeW4rkafTm8M0CGrV+w52Fhz32yJP+hKklaWX5CVZJayHCXpBYamHCf73QGmfHvmvWPJ/nllaizn7ro+Z82vT6e5M+SvGUl6uynbk9bkeRvJTnXfKZioHXTc5KxJI8lOZHkvy13jf3Wxb/ty5P8lyTfaHr+9ZWos1+SPJjkbJIn5ljf//yqqtf8FzP/Kfu/gL8CvB74BrD5vG1uBb7MzHvs3wp8baXrXoae/zZwZXP/HcPQc8d2fwJ8Cfi1la57GV7nK4AngV9olq9d6bqXoecPAP+2uX8N8CLw+pWuvYee/x7wy8ATc6zve34Nyp57N6cz2Ab8+5rxCHBFkrXLXWgfzdtzVf1ZVb3ULD7CzOcJBlm3p634DeCzwNnlLG6JdNPzPwE+V1XPAVTVoPfdTc8FvDFJgDXMhPv08pbZP1X1MDM9zKXv+TUo4X4d8J2O5VPN2EK3GSQL7ecuZn7zD7J5e05yHfBO4A+Wsa6l1M3r/CbgyiSTSY4lefeyVbc0uun5Y8AvMvPhx+PA+6vqx8tT3oroe34t1ekH+m3e0xl0uc0g6bqfJFuZCfe/s6QVLb1uev494Leq6tzMTt3A66bn1wE3AjcDlwFfTfJIVf3PpS5uiXTT8y3AY8Dbgb8KPJTkv1fVD5a4tpXS9/walHDv5nQGbTvlQVf9JPmbwCeBd1TV95aptqXSTc+jwEQT7FcDtyaZrqr/vCwV9l+3/7a/W1WvAK8keRh4CzCo4d5Nz78OfKRmDkifTPIM8DeAo8tT4rLre34NymGZbk5ncBh4d/O/zm8FXq6qF5a70D6at+ckvwB8DrhjgPfiOs3bc1VtrKoNVbUB+AzwLwc42KG7f9uHgL+b5HVJ/gLwK8BTy1xnP3XT83PM/KVCkhFmzhz77WWtcnn1Pb8GYs+95jidQZJ/0az/A2beOXErcBL4v8z85h9YXfb8b4C/BNzf7MlO1wCfUa/Lnlulm56r6qkkfwQ8DvwY+GRVzfqWukHQ5ev8YWBfkuPMHLL4raoa2FMBJ/k0MAZcneQU8EHgEli6/PL0A5LUQoNyWEaStACGuyS1kOEuSS1kuEtSCxnuktRChrsktZDhLkkt9P8BcU2Ho47HHvYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "viet['vietx'].hist(bins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13105f7",
   "metadata": {},
   "source": [
    "The full sample appears to have more people who gave an intermediate answer and a more pro-war answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20560416",
   "metadata": {},
   "source": [
    "Let's do a version of the graph from the paper that looks at the relationship between draft number and the war attitude index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5436ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='lotnum', ylabel='vietx'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x='lotnum', y='vietx', data=colnomil, ci=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e11db6",
   "metadata": {},
   "source": [
    "As we an see, there is a postive relationship, meaning those with higher lottery numbers (less likely to be drafted) are more pro-war. We can also use `smf.ols` to produce this bivariate regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82f864b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>vietx</td>      <th>  R-squared:         </th> <td>   0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 20 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:40:09</td>     <th>  Log-Likelihood:    </th> <td> -75.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   256</td>      <th>  AIC:               </th> <td>   155.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   254</td>      <th>  BIC:               </th> <td>   163.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.2058</td> <td>    0.042</td> <td>    4.880</td> <td> 0.000</td> <td>    0.123</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lotnum</th>    <td>    0.0006</td> <td>    0.000</td> <td>    3.260</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>26.307</td> <th>  Durbin-Watson:     </th> <td>   1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  24.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.681</td> <th>  Prob(JB):          </th> <td>5.52e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.356</td> <th>  Cond. No.          </th> <td>    439.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  vietx   R-squared:                       0.040\n",
       "Model:                            OLS   Adj. R-squared:                  0.036\n",
       "Method:                 Least Squares   F-statistic:                     10.63\n",
       "Date:                Mon, 20 Mar 2023   Prob (F-statistic):            0.00127\n",
       "Time:                        10:40:09   Log-Likelihood:                -75.945\n",
       "No. Observations:                 256   AIC:                             155.9\n",
       "Df Residuals:                     254   BIC:                             163.0\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.2058      0.042      4.880      0.000       0.123       0.289\n",
       "lotnum         0.0006      0.000      3.260      0.001       0.000       0.001\n",
       "==============================================================================\n",
       "Omnibus:                       26.307   Durbin-Watson:                   1.923\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.214\n",
       "Skew:                           0.681   Prob(JB):                     5.52e-06\n",
       "Kurtosis:                       2.356   Cond. No.                         439.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hawk_m1  = smf.ols('vietx ~ lotnum', data=colnomil).fit()\n",
    "hawk_m1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee5001d",
   "metadata": {},
   "source": [
    "We can compute the predicted change in going from the lowest draft number (1) to an average draft number (184) by multipling this difference times the slope parameter, which we can access with `hawk_m1.params`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6095ecfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11847010895621259"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hawk_m1.params[1]*(184  - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f310ecee",
   "metadata": {},
   "source": [
    "**Question 3.2. What is the predicted shift in pro-war attitude when going from the lowest draft number (1) to the highest (366)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8c89264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23629284026785569"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hawk_m1.params[1]*(366  - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887196a9",
   "metadata": {},
   "source": [
    "For a later regression, it will be helpful to use a version of the lottery number which is *normalized* to range from 0 to 1, where 0 corresponds to the lowest number and 1 the highest number. The authors have done this with a variable called `lotnum01`. To visualize this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dabd15eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='lotnum', ylabel='lotnum01'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x='lotnum', y='lotnum01', data=colnomil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a9b96f",
   "metadata": {},
   "source": [
    "**Question 3.3. Use `smf.ols` to tun a bivariate regression with `vietx` as the dependent variable and `lotnum01` as the independent variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4100cf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>vietx</td>      <th>  R-squared:         </th> <td>   0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 20 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:44:11</td>     <th>  Log-Likelihood:    </th> <td> -75.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   256</td>      <th>  AIC:               </th> <td>   155.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   254</td>      <th>  BIC:               </th> <td>   163.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.2065</td> <td>    0.042</td> <td>    4.915</td> <td> 0.000</td> <td>    0.124</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lotnum01</th>  <td>    0.2363</td> <td>    0.072</td> <td>    3.260</td> <td> 0.001</td> <td>    0.094</td> <td>    0.379</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>26.307</td> <th>  Durbin-Watson:     </th> <td>   1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  24.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.681</td> <th>  Prob(JB):          </th> <td>5.52e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.356</td> <th>  Cond. No.          </th> <td>    4.52</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  vietx   R-squared:                       0.040\n",
       "Model:                            OLS   Adj. R-squared:                  0.036\n",
       "Method:                 Least Squares   F-statistic:                     10.63\n",
       "Date:                Mon, 20 Mar 2023   Prob (F-statistic):            0.00127\n",
       "Time:                        10:44:11   Log-Likelihood:                -75.945\n",
       "No. Observations:                 256   AIC:                             155.9\n",
       "Df Residuals:                     254   BIC:                             163.0\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.2065      0.042      4.915      0.000       0.124       0.289\n",
       "lotnum01       0.2363      0.072      3.260      0.001       0.094       0.379\n",
       "==============================================================================\n",
       "Omnibus:                       26.307   Durbin-Watson:                   1.923\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.214\n",
       "Skew:                           0.681   Prob(JB):                     5.52e-06\n",
       "Kurtosis:                       2.356   Cond. No.                         4.52\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('vietx ~ lotnum01', data=colnomil).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e502c9",
   "metadata": {},
   "source": [
    "The slope you get from this should be the same as what you got question 3.2. This is reassuring: once we normalize the lottery number to be between 0 and 1, the slope tells us the change in the prediction of war attitudes as `lotnum01` goes up by one unit (i.e., the lowest to highest value). In other words, the change in predicted war attitude as we go from the lowest to highest lottery number isn't affected by whether we use the \"raw number\" or 0 to 1 version. \n",
    "\n",
    "From this analysis, we can be confident that having a lower draft number caused more anti-war attitudes. We know there is no selection bias because the lottery number was random, and so it should be unrelated to the potential outcomes. \n",
    "\n",
    "Some papers argue that the effect of having a low draft number can be used to estimate the causal effect of military service (on things like <a href=\"https://www.jstor.org/stable/2006669\">lifetime wages</a>). Erikson and Stoker argue that for the case of political attitudes, it may make more sense to think about the lottery number itself as causing the change in attitudes, since having a low lottery number could induce fear/anxiety about getting drafted regardless of whether that actually happens.\n",
    "\n",
    "**Question 3.4. One way to explore this empirically is to run a multivariate regression with `vietx` as the dependent variable and `lotnum01` and `milserv` (which is equal to 1 for those who ended up serving in the military and 0 for those who did not) as independent variables. Use `smf.ols` to run this regression. (Recall for multivariate regression the \"formula\" argument should look like `DV ~ IV1 + IV2`.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7e6e7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>vietx</td>      <th>  R-squared:         </th> <td>   0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 20 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:45:40</td>     <th>  Log-Likelihood:    </th> <td> -75.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   255</td>      <th>  AIC:               </th> <td>   157.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   252</td>      <th>  BIC:               </th> <td>   168.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1909</td> <td>    0.046</td> <td>    4.155</td> <td> 0.000</td> <td>    0.100</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lotnum01</th>  <td>    0.2418</td> <td>    0.073</td> <td>    3.305</td> <td> 0.001</td> <td>    0.098</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>milserv</th>   <td>    0.0379</td> <td>    0.044</td> <td>    0.861</td> <td> 0.390</td> <td>   -0.049</td> <td>    0.125</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>25.150</td> <th>  Durbin-Watson:     </th> <td>   1.927</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  24.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.697</td> <th>  Prob(JB):          </th> <td>4.89e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.400</td> <th>  Cond. No.          </th> <td>    4.84</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  vietx   R-squared:                       0.042\n",
       "Model:                            OLS   Adj. R-squared:                  0.035\n",
       "Method:                 Least Squares   F-statistic:                     5.590\n",
       "Date:                Mon, 20 Mar 2023   Prob (F-statistic):            0.00421\n",
       "Time:                        10:45:40   Log-Likelihood:                -75.702\n",
       "No. Observations:                 255   AIC:                             157.4\n",
       "Df Residuals:                     252   BIC:                             168.0\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1909      0.046      4.155      0.000       0.100       0.281\n",
       "lotnum01       0.2418      0.073      3.305      0.001       0.098       0.386\n",
       "milserv        0.0379      0.044      0.861      0.390      -0.049       0.125\n",
       "==============================================================================\n",
       "Omnibus:                       25.150   Durbin-Watson:                   1.927\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.455\n",
       "Skew:                           0.697   Prob(JB):                     4.89e-06\n",
       "Kurtosis:                       2.400   Cond. No.                         4.84\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('vietx ~ lotnum01 + milserv', data=colnomil).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a861e",
   "metadata": {},
   "source": [
    "A nice thing about using the 0 to 1 version of `lotnum` is we can compare the coefficients here, since `milserv` also ranges from 0 to 1. As we can see, the lottery number itself seemed to have a much larger impact on attitudes then whether the responded actually served in the military! Further, the coefficient on `lotnum01` is about the same as it was without controlling for `milserv`.\n",
    "\n",
    "Recall an important assumption for us to try and estimate the effect of military service on an outcome (like war attitudes) is that our instrument (here, lottery number) only affects the outcome by changing the treatment (here, military service). This is called the *exclusion restriction.* While there is no direct way to test this assumption, the analysis here raises a red flag: not only does the lottery number seem to influence attitudes *holding military service fixed*, military service does not seem to help us predict war attitudes.\n",
    "\n",
    "Another thing we might want to explore is how good of a job the lottery number does at predicting whether someone serves in the military. \n",
    "\n",
    "**Question 3.5. Use `smf.ols` to run a bivariate regression with `milserv` as the dependent variable and `lotnum01` as the independent variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cbecb32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>milserv</td>     <th>  R-squared:         </th> <td>   0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 20 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>0.0778</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:46:24</td>     <th>  Log-Likelihood:    </th> <td> -168.53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   259</td>      <th>  AIC:               </th> <td>   341.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   257</td>      <th>  BIC:               </th> <td>   348.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.4124</td> <td>    0.059</td> <td>    6.937</td> <td> 0.000</td> <td>    0.295</td> <td>    0.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lotnum01</th>  <td>   -0.1816</td> <td>    0.103</td> <td>   -1.771</td> <td> 0.078</td> <td>   -0.384</td> <td>    0.020</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>622.133</td> <th>  Durbin-Watson:     </th> <td>   1.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  44.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.753</td>  <th>  Prob(JB):          </th> <td>1.73e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.623</td>  <th>  Cond. No.          </th> <td>    4.51</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                milserv   R-squared:                       0.012\n",
       "Model:                            OLS   Adj. R-squared:                  0.008\n",
       "Method:                 Least Squares   F-statistic:                     3.136\n",
       "Date:                Mon, 20 Mar 2023   Prob (F-statistic):             0.0778\n",
       "Time:                        10:46:24   Log-Likelihood:                -168.53\n",
       "No. Observations:                 259   AIC:                             341.1\n",
       "Df Residuals:                     257   BIC:                             348.2\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.4124      0.059      6.937      0.000       0.295       0.530\n",
       "lotnum01      -0.1816      0.103     -1.771      0.078      -0.384       0.020\n",
       "==============================================================================\n",
       "Omnibus:                      622.133   Durbin-Watson:                   1.886\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               44.958\n",
       "Skew:                           0.753   Prob(JB):                     1.73e-10\n",
       "Kurtosis:                       1.623   Cond. No.                         4.51\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('milserv ~ lotnum01', data=colnomil).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc4ee9",
   "metadata": {},
   "source": [
    "You should find a negative coefficient on `lotnum01`, but the magnitude is smaller than we might expect: going from the lowest to the highest lottery number only decreases the chance of getting drafted by less than 20%. (Compare this to the KIPP lottery where winning inceased the chance of enrolling by about 75%). \n",
    "\n",
    "Recall another important assumption if we want to estimate the effect of military service on war attitudes is that there is a \"strong first stage\". While there are no absolute rules here, one rule of thumb is that the F statistic (reported in the top right of the output) is at least 10, which it is not. \n",
    "\n",
    "So there are two reasons we should not use this data to estimate the effect of *military service* on war attitudes: (1) the exclusion restriction is probably not met, and (2) there is a \"weak\" first stage relationship.\n",
    "\n",
    "However, we can still learn about the effect of *the threat of being drafted* on war attitues, and be confident that this effect represents a causal relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51354694",
   "metadata": {},
   "source": [
    "## Part 4: Is college worth it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d845b8e9",
   "metadata": {},
   "source": [
    "To get a bit of practice using two-stage least squares for an example where it is arguably more appropriate, let's turn to a paper by Berkeley's recent Nobel Laureate David Card. \n",
    "\n",
    "<a href=\"https://davidcard.berkeley.edu/papers/geo_var_schooling.pdf\">This paper</a> studies a classic policy question in the social sciences: what is the impact of education on earnings? \n",
    "\n",
    "We can just run a regression with earnings as the DV and years of education as the IV, but there are some obvious reasons to be worried about selection bias: those who get more education are different on other dimensions (having the resources to attend college, intelligence, work ethic, etc.).\n",
    "\n",
    "Card proposes using *growing up in a county with a college* as an instrument which affects how much education one gets. The core idea is that when college is closer, it is easier to attend, particularly for those with family obligations. \n",
    "\n",
    "Let's load up the data, which I'm getting from Scott Cunningham's <a href=\"https://mixtape.scunning.com/\">\"Causal Inference Mixtape\"</a>, which is a great (and free!) book if you'd like to explore the topics we are covering with more technical detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fec66de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nearc2</th>\n",
       "      <th>nearc4</th>\n",
       "      <th>educ</th>\n",
       "      <th>age</th>\n",
       "      <th>fatheduc</th>\n",
       "      <th>motheduc</th>\n",
       "      <th>weight</th>\n",
       "      <th>momdad14</th>\n",
       "      <th>sinmom14</th>\n",
       "      <th>...</th>\n",
       "      <th>KWW</th>\n",
       "      <th>IQ</th>\n",
       "      <th>married</th>\n",
       "      <th>libcrd14</th>\n",
       "      <th>exper</th>\n",
       "      <th>lwage</th>\n",
       "      <th>expersq</th>\n",
       "      <th>u_lwage</th>\n",
       "      <th>lwage_hat</th>\n",
       "      <th>u_educ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158413.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.306275</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.198047</td>\n",
       "      <td>6.108228</td>\n",
       "      <td>-3.067539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>380166.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.175867</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-0.211160</td>\n",
       "      <td>6.387027</td>\n",
       "      <td>-1.727562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>367470.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.580639</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.204719</td>\n",
       "      <td>6.375920</td>\n",
       "      <td>1.012975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>380166.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.521461</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.967905</td>\n",
       "      <td>6.489366</td>\n",
       "      <td>-2.253536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>367470.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.591674</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.125173</td>\n",
       "      <td>6.466501</td>\n",
       "      <td>1.090437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>5218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>82135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.814130</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-0.289775</td>\n",
       "      <td>6.103905</td>\n",
       "      <td>-1.505588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>5219.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88765.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.175867</td>\n",
       "      <td>225.0</td>\n",
       "      <td>-0.137418</td>\n",
       "      <td>6.313285</td>\n",
       "      <td>2.214089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>5220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89271.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.214608</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.135805</td>\n",
       "      <td>6.078803</td>\n",
       "      <td>-1.907211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>5221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110376.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.569481</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.408375</td>\n",
       "      <td>6.161106</td>\n",
       "      <td>0.868737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>5225.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81081.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.263398</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.427185</td>\n",
       "      <td>5.836213</td>\n",
       "      <td>0.413897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3010 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  nearc2  nearc4  educ   age  fatheduc  motheduc    weight  \\\n",
       "0        2.0     0.0     0.0   7.0  29.0       NaN       NaN  158413.0   \n",
       "1        3.0     0.0     0.0  12.0  27.0       8.0       8.0  380166.0   \n",
       "2        4.0     0.0     0.0  12.0  34.0      14.0      12.0  367470.0   \n",
       "3        5.0     1.0     1.0  11.0  27.0      11.0      12.0  380166.0   \n",
       "4        6.0     1.0     1.0  12.0  34.0       8.0       7.0  367470.0   \n",
       "...      ...     ...     ...   ...   ...       ...       ...       ...   \n",
       "3005  5218.0     0.0     1.0  12.0  25.0       8.0      12.0   82135.0   \n",
       "3006  5219.0     0.0     1.0  13.0  34.0       NaN       NaN   88765.0   \n",
       "3007  5220.0     0.0     1.0  12.0  24.0      11.0       NaN   89271.0   \n",
       "3008  5221.0     0.0     1.0  12.0  31.0       NaN       NaN  110376.0   \n",
       "3009  5225.0     0.0     1.0  13.0  26.0       NaN       NaN   81081.0   \n",
       "\n",
       "      momdad14  sinmom14  ...   KWW     IQ  married  libcrd14  exper  \\\n",
       "0          1.0       0.0  ...  15.0    NaN      1.0       0.0   16.0   \n",
       "1          1.0       0.0  ...  35.0   93.0      1.0       1.0    9.0   \n",
       "2          1.0       0.0  ...  42.0  103.0      1.0       1.0   16.0   \n",
       "3          1.0       0.0  ...  25.0   88.0      1.0       1.0   10.0   \n",
       "4          1.0       0.0  ...  34.0  108.0      1.0       0.0   16.0   \n",
       "...        ...       ...  ...   ...    ...      ...       ...    ...   \n",
       "3005       1.0       0.0  ...  15.0    NaN      1.0       0.0    7.0   \n",
       "3006       1.0       0.0  ...  43.0    NaN      1.0       1.0   15.0   \n",
       "3007       0.0       0.0  ...  25.0  109.0      1.0       0.0    6.0   \n",
       "3008       1.0       0.0  ...  32.0  107.0      1.0       1.0   13.0   \n",
       "3009       0.0       0.0  ...  27.0    NaN      1.0       0.0    7.0   \n",
       "\n",
       "         lwage  expersq   u_lwage  lwage_hat    u_educ  \n",
       "0     6.306275    256.0  0.198047   6.108228 -3.067539  \n",
       "1     6.175867     81.0 -0.211160   6.387027 -1.727562  \n",
       "2     6.580639    256.0  0.204719   6.375920  1.012975  \n",
       "3     5.521461    100.0 -0.967905   6.489366 -2.253536  \n",
       "4     6.591674    256.0  0.125173   6.466501  1.090437  \n",
       "...        ...      ...       ...        ...       ...  \n",
       "3005  5.814130     49.0 -0.289775   6.103905 -1.505588  \n",
       "3006  6.175867    225.0 -0.137418   6.313285  2.214089  \n",
       "3007  6.214608     36.0  0.135805   6.078803 -1.907211  \n",
       "3008  6.569481    169.0  0.408375   6.161106  0.868737  \n",
       "3009  6.263398     49.0  0.427185   5.836213  0.413897  \n",
       "\n",
       "[3010 rows x 37 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "def read_data(file): \n",
    "    return pd.read_stata(\"https://raw.github.com/scunning1975/mixtape/master/\" + file)\n",
    "card = read_data(\"card.dta\")\n",
    "card"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b26a41",
   "metadata": {},
   "source": [
    "Fist let's look at the bivariate relationship between years of education (`educ`) and the natural log of wages (`lwage`). Economists and other social scientists often use the natural log of wages rather than the \"raw\" measure of wages for reasons we'll discuss in a few weeks. For now, the important thing to know is that we can interpret the coefficient as telling us the *percent increase* in wage as education goes up by one year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c64f01ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   329.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 20 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>5.77e-70</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:47:04</td>     <th>  Log-Likelihood:    </th> <td> -1668.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3010</td>      <th>  AIC:               </th> <td>   3342.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3008</td>      <th>  BIC:               </th> <td>   3354.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    5.5709</td> <td>    0.039</td> <td>  143.470</td> <td> 0.000</td> <td>    5.495</td> <td>    5.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0521</td> <td>    0.003</td> <td>   18.153</td> <td> 0.000</td> <td>    0.046</td> <td>    0.058</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>23.139</td> <th>  Durbin-Watson:     </th> <td>   1.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  24.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.186</td> <th>  Prob(JB):          </th> <td>5.17e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.236</td> <th>  Cond. No.          </th> <td>    68.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.099\n",
       "Model:                            OLS   Adj. R-squared:                  0.098\n",
       "Method:                 Least Squares   F-statistic:                     329.5\n",
       "Date:                Mon, 20 Mar 2023   Prob (F-statistic):           5.77e-70\n",
       "Time:                        10:47:04   Log-Likelihood:                -1668.8\n",
       "No. Observations:                3010   AIC:                             3342.\n",
       "Df Residuals:                    3008   BIC:                             3354.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      5.5709      0.039    143.470      0.000       5.495       5.647\n",
       "educ           0.0521      0.003     18.153      0.000       0.046       0.058\n",
       "==============================================================================\n",
       "Omnibus:                       23.139   Durbin-Watson:                   1.725\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.345\n",
       "Skew:                          -0.186   Prob(JB):                     5.17e-06\n",
       "Kurtosis:                       3.236   Cond. No.                         68.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols(\"lwage ~ educ\", data = card).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b6021",
   "metadata": {},
   "source": [
    "So, this implies that an extra year of education is associated with a 5% increase in wages. \n",
    "\n",
    "We can also control for some other variables we think might matter (gender, whether one is married, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "688c104a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.305</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.304</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   219.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 20 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>1.97e-232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:47:12</td>     <th>  Log-Likelihood:    </th> <td> -1273.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3003</td>      <th>  AIC:               </th> <td>   2562.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2996</td>      <th>  BIC:               </th> <td>   2604.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    5.0633</td> <td>    0.064</td> <td>   79.437</td> <td> 0.000</td> <td>    4.938</td> <td>    5.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0712</td> <td>    0.003</td> <td>   20.438</td> <td> 0.000</td> <td>    0.064</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>     <td>    0.0342</td> <td>    0.002</td> <td>   15.422</td> <td> 0.000</td> <td>    0.030</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>   -0.1660</td> <td>    0.018</td> <td>   -9.426</td> <td> 0.000</td> <td>   -0.201</td> <td>   -0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>south</th>     <td>   -0.1316</td> <td>    0.015</td> <td>   -8.788</td> <td> 0.000</td> <td>   -0.161</td> <td>   -0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>   <td>   -0.0359</td> <td>    0.003</td> <td>  -10.547</td> <td> 0.000</td> <td>   -0.043</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smsa</th>      <td>    0.1758</td> <td>    0.015</td> <td>   11.372</td> <td> 0.000</td> <td>    0.145</td> <td>    0.206</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>53.196</td> <th>  Durbin-Watson:     </th> <td>   1.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  69.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.231</td> <th>  Prob(JB):          </th> <td>8.38e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.584</td> <th>  Cond. No.          </th> <td>    154.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.305\n",
       "Model:                            OLS   Adj. R-squared:                  0.304\n",
       "Method:                 Least Squares   F-statistic:                     219.2\n",
       "Date:                Mon, 20 Mar 2023   Prob (F-statistic):          1.97e-232\n",
       "Time:                        10:47:12   Log-Likelihood:                -1273.9\n",
       "No. Observations:                3003   AIC:                             2562.\n",
       "Df Residuals:                    2996   BIC:                             2604.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      5.0633      0.064     79.437      0.000       4.938       5.188\n",
       "educ           0.0712      0.003     20.438      0.000       0.064       0.078\n",
       "exper          0.0342      0.002     15.422      0.000       0.030       0.038\n",
       "black         -0.1660      0.018     -9.426      0.000      -0.201      -0.131\n",
       "south         -0.1316      0.015     -8.788      0.000      -0.161      -0.102\n",
       "married       -0.0359      0.003    -10.547      0.000      -0.043      -0.029\n",
       "smsa           0.1758      0.015     11.372      0.000       0.145       0.206\n",
       "==============================================================================\n",
       "Omnibus:                       53.196   Durbin-Watson:                   1.858\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               69.430\n",
       "Skew:                          -0.231   Prob(JB):                     8.38e-16\n",
       "Kurtosis:                       3.584   Cond. No.                         154.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols(\"lwage ~ educ + exper + black + south + married + smsa\", \n",
    "        data = card).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a5a6e3",
   "metadata": {},
   "source": [
    "Now we get a somewhat *higher* coefficient, meaning that keeping these other variables fixed, another year of education is associated with an increase in wages of 7%. \n",
    "\n",
    "While we are going to keep focusing on education here, another result from this regression that could pique your interest is the coefficient on `black`, which indicates that even keeping fixed education and other relevant variables, black respondents earn about 16% less on average. Whether results like this are direct evidence of discrimination is a heavily debated topic.\n",
    "\n",
    "Now let's turn to the \"growing up near college\" instrument. First we will use a variable `nearc4`, which is equal to 1 if the county one grew up in has a 4 year college and 0 otherwise. Let's run our \"first stage\" to see how this affects years of education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "653a80d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>educ</td>       <th>  R-squared:         </th> <td>   0.021</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.020</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   63.91</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 20 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>1.84e-15</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:47:28</td>     <th>  Log-Likelihood:    </th> <td> -7202.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3010</td>      <th>  AIC:               </th> <td>1.441e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3008</td>      <th>  BIC:               </th> <td>1.442e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   12.6980</td> <td>    0.086</td> <td>  148.269</td> <td> 0.000</td> <td>   12.530</td> <td>   12.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nearc4</th>    <td>    0.8290</td> <td>    0.104</td> <td>    7.994</td> <td> 0.000</td> <td>    0.626</td> <td>    1.032</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>26.936</td> <th>  Durbin-Watson:     </th> <td>   1.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  28.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.204</td> <th>  Prob(JB):          </th> <td>6.90e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.243</td> <th>  Cond. No.          </th> <td>    3.31</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   educ   R-squared:                       0.021\n",
       "Model:                            OLS   Adj. R-squared:                  0.020\n",
       "Method:                 Least Squares   F-statistic:                     63.91\n",
       "Date:                Mon, 20 Mar 2023   Prob (F-statistic):           1.84e-15\n",
       "Time:                        10:47:28   Log-Likelihood:                -7202.7\n",
       "No. Observations:                3010   AIC:                         1.441e+04\n",
       "Df Residuals:                    3008   BIC:                         1.442e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     12.6980      0.086    148.269      0.000      12.530      12.866\n",
       "nearc4         0.8290      0.104      7.994      0.000       0.626       1.032\n",
       "==============================================================================\n",
       "Omnibus:                       26.936   Durbin-Watson:                   1.626\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.373\n",
       "Skew:                          -0.204   Prob(JB):                     6.90e-07\n",
       "Kurtosis:                       3.243   Cond. No.                         3.31\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_fs_reg = smf.ols(\"educ ~ nearc4\", data = card).fit()\n",
    "ols_fs_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af72b4da",
   "metadata": {},
   "source": [
    "And our \"reduced form\" uses log wages as the dependent variable and growing up near a four year college as the depedent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2b6e7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   82.74</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 20 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>1.65e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:47:37</td>     <th>  Log-Likelihood:    </th> <td> -1784.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3010</td>      <th>  AIC:               </th> <td>   3573.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3008</td>      <th>  BIC:               </th> <td>   3585.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    6.1555</td> <td>    0.014</td> <td>  434.865</td> <td> 0.000</td> <td>    6.128</td> <td>    6.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nearc4</th>    <td>    0.1559</td> <td>    0.017</td> <td>    9.096</td> <td> 0.000</td> <td>    0.122</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17.754</td> <th>  Durbin-Watson:     </th> <td>   1.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  18.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.166</td> <th>  Prob(JB):          </th> <td>0.000107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.187</td> <th>  Cond. No.          </th> <td>    3.31</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.027\n",
       "Model:                            OLS   Adj. R-squared:                  0.026\n",
       "Method:                 Least Squares   F-statistic:                     82.74\n",
       "Date:                Mon, 20 Mar 2023   Prob (F-statistic):           1.65e-19\n",
       "Time:                        10:47:37   Log-Likelihood:                -1784.4\n",
       "No. Observations:                3010   AIC:                             3573.\n",
       "Df Residuals:                    3008   BIC:                             3585.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      6.1555      0.014    434.865      0.000       6.128       6.183\n",
       "nearc4         0.1559      0.017      9.096      0.000       0.122       0.190\n",
       "==============================================================================\n",
       "Omnibus:                       17.754   Durbin-Watson:                   1.661\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.291\n",
       "Skew:                          -0.166   Prob(JB):                     0.000107\n",
       "Kurtosis:                       3.187   Cond. No.                         3.31\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_rf_reg = smf.ols(\"lwage ~ nearc4\", data = card).fit()\n",
    "ols_rf_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d62bfd",
   "metadata": {},
   "source": [
    "We can compute the two-stage least squares estimate of the causal effect of an extra year of college \"by hand\" by dividing the slope on `nearc4` in the regression with log wages as the dependent variable (analogous to `rho`) by the slope on `nearc4` in the regression with years of education as the dependent variable (analogous to `phi`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0595b4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1880626042311915"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_rf_reg.params[1]/ols_fs_reg.params[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801bd348",
   "metadata": {},
   "source": [
    "Now lets use the IV2SLS function from the linearmodels.iv library (already loaded up) to do this a bit more efficiently. \n",
    "\n",
    "If we want to estimate the causal effect of `treat` on `outcome` with instrument `instrument`, all of which are variables in a data frame `df`, the code we can use is:\n",
    "\n",
    "`iv = IV2SLS.from_formula(\"outcome ~ 1 + [treat ~ instrument]\", df).fit()`\n",
    "\n",
    "Using the `.from_formula` allows us to specify our regression with a formula relatively similar to what we have been doing with `smf.ols`. Like before, we start our formula with `outcome ~`, but then there are two differences. First, we have to add a `1+` after the tilde; in short, this makes sure that we include a term for the y intercept (the $a$ or $\\alpha$ from the slides). Second, we indicate what to use as the first stage by putting `[treat ~ instrument]` rather than just `treat`. \n",
    "\n",
    "To get output we then use the `summary` function:\n",
    "\n",
    "`iv.summary`\n",
    "\n",
    "Note that unlike with `smf.ols`, we don't add a `()` after the summary. \n",
    "\n",
    "Here is how it looks for a regresion with log wages as the outcome, education as the treatment, and growing up near a 4 year college as the instrument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3af50457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>IV-2SLS Estimation Summary</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>-0.5739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>-0.5744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>3010</td>       <th>  F-statistic:       </th> <td>51.784</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, Mar 20 2023</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:48:07</td>     <th>  Distribution:      </th> <td>chi2(1)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cov. Estimator:</th>        <td>robust</td>      <th>                     </th>    <td></td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td></td>         <th>                     </th>    <td></td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Parameter Estimates</caption>\n",
       "<tr>\n",
       "      <td></td>      <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th> <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>3.7675</td>    <td>0.3466</td>   <td>10.869</td> <td>0.0000</td>   <td>3.0881</td>   <td>4.4468</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>       <td>0.1881</td>    <td>0.0261</td>   <td>7.1961</td> <td>0.0000</td>   <td>0.1368</td>   <td>0.2393</td> \n",
       "</tr>\n",
       "</table><br/><br/>Endogenous: educ<br/>Instruments: nearc4<br/>Robust Covariance (Heteroskedastic)<br/>Debiased: False"
      ],
      "text/plain": [
       "<class 'linearmodels.compat.statsmodels.Summary'>\n",
       "\"\"\"\n",
       "                          IV-2SLS Estimation Summary                          \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                     -0.5739\n",
       "Estimator:                    IV-2SLS   Adj. R-squared:                -0.5744\n",
       "No. Observations:                3010   F-statistic:                    51.784\n",
       "Date:                Mon, Mar 20 2023   P-value (F-stat)                0.0000\n",
       "Time:                        10:48:07   Distribution:                  chi2(1)\n",
       "Cov. Estimator:                robust                                         \n",
       "                                                                              \n",
       "                             Parameter Estimates                              \n",
       "==============================================================================\n",
       "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      3.7675     0.3466     10.869     0.0000      3.0881      4.4468\n",
       "educ           0.1881     0.0261     7.1961     0.0000      0.1368      0.2393\n",
       "==============================================================================\n",
       "\n",
       "Endogenous: educ\n",
       "Instruments: nearc4\n",
       "Robust Covariance (Heteroskedastic)\n",
       "Debiased: False\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_c4 = IV2SLS.from_formula(\"lwage ~ 1+[educ ~ nearc4 ]\", card).fit()\n",
    "iv_c4.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d901d5a",
   "metadata": {},
   "source": [
    "The coefficient is the same as we got above!\n",
    "\n",
    "Another advantage to doing this with 2SLS is we can add other control variables (as discused in the book, to both the first stage and second stage). To do that, we use a similar line of code from before, but add `+V1 + V2 + ...` for the other control varibles. The treatment variable and the instrument still get entered as `[treat ~ instrument]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64b8169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/opt/anaconda3/lib/python3.9/site-packages/linearmodels/iv/model.py:543: MissingValueWarning: \n",
      "Inputs contain missing values. Dropping rows with missing observations.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>IV-2SLS Estimation Summary</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>0.2513</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>0.2498</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>3003</td>       <th>  F-statistic:       </th> <td>892.71</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, Mar 20 2023</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:48:22</td>     <th>  Distribution:      </th> <td>chi2(6)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cov. Estimator:</th>        <td>robust</td>      <th>                     </th>    <td></td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td></td>         <th>                     </th>    <td></td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Parameter Estimates</caption>\n",
       "<tr>\n",
       "      <td></td>      <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th>  <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>4.1625</td>    <td>0.8349</td>   <td>4.9857</td>  <td>0.0000</td>   <td>2.5262</td>   <td>5.7988</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>      <td>-0.1157</td>   <td>0.0496</td>   <td>-2.3343</td> <td>0.0196</td>   <td>-0.2128</td>  <td>-0.0186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>      <td>0.0556</td>    <td>0.0199</td>   <td>2.7980</td>  <td>0.0051</td>   <td>0.0166</td>   <td>0.0945</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>    <td>-0.0320</td>   <td>0.0051</td>   <td>-6.3037</td> <td>0.0000</td>   <td>-0.0419</td>  <td>-0.0220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smsa</th>       <td>0.1477</td>    <td>0.0303</td>   <td>4.8721</td>  <td>0.0000</td>   <td>0.0883</td>   <td>0.2071</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>south</th>      <td>-0.1132</td>   <td>0.0229</td>   <td>-4.9314</td> <td>0.0000</td>   <td>-0.1581</td>  <td>-0.0682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>       <td>0.1242</td>    <td>0.0492</td>   <td>2.5258</td>  <td>0.0115</td>   <td>0.0278</td>   <td>0.2205</td> \n",
       "</tr>\n",
       "</table><br/><br/>Endogenous: educ<br/>Instruments: nearc4<br/>Robust Covariance (Heteroskedastic)<br/>Debiased: False"
      ],
      "text/plain": [
       "<class 'linearmodels.compat.statsmodels.Summary'>\n",
       "\"\"\"\n",
       "                          IV-2SLS Estimation Summary                          \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                      0.2513\n",
       "Estimator:                    IV-2SLS   Adj. R-squared:                 0.2498\n",
       "No. Observations:                3003   F-statistic:                    892.71\n",
       "Date:                Mon, Mar 20 2023   P-value (F-stat)                0.0000\n",
       "Time:                        10:48:22   Distribution:                  chi2(6)\n",
       "Cov. Estimator:                robust                                         \n",
       "                                                                              \n",
       "                             Parameter Estimates                              \n",
       "==============================================================================\n",
       "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      4.1625     0.8349     4.9857     0.0000      2.5262      5.7988\n",
       "black         -0.1157     0.0496    -2.3343     0.0196     -0.2128     -0.0186\n",
       "exper          0.0556     0.0199     2.7980     0.0051      0.0166      0.0945\n",
       "married       -0.0320     0.0051    -6.3037     0.0000     -0.0419     -0.0220\n",
       "smsa           0.1477     0.0303     4.8721     0.0000      0.0883      0.2071\n",
       "south         -0.1132     0.0229    -4.9314     0.0000     -0.1581     -0.0682\n",
       "educ           0.1242     0.0492     2.5258     0.0115      0.0278      0.2205\n",
       "==============================================================================\n",
       "\n",
       "Endogenous: educ\n",
       "Instruments: nearc4\n",
       "Robust Covariance (Heteroskedastic)\n",
       "Debiased: False\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2SLS\n",
    "iv_c4_mv = IV2SLS.from_formula(\"lwage ~ 1 + exper + black + south + married + smsa + [educ ~ nearc4 ]\", \n",
    "                               data=card).fit()\n",
    "iv_c4_mv.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6dd1f0",
   "metadata": {},
   "source": [
    "Again, we estimate a strong causal effect of increasing years education (via growing up close to a 4 year college). In fact, the cofficient on `educ` is even higher than in the regular regression.\n",
    "\n",
    "We can also look at the effect of growing up near a 2 year college, which is captured by the `nearc2` variable. \n",
    "\n",
    "**Question 4.1 Use `IV2SLS.from_formula` to run the regression with log wages as the outcome, education as the treatment, and `nearc2` as the instrument (with no control variables).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17ee62f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>IV-2SLS Estimation Summary</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>-0.5739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>-0.5744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>3010</td>       <th>  F-statistic:       </th> <td>51.784</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, Mar 21 2023</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:25:48</td>     <th>  Distribution:      </th> <td>chi2(1)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cov. Estimator:</th>        <td>robust</td>      <th>                     </th>    <td></td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td></td>         <th>                     </th>    <td></td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Parameter Estimates</caption>\n",
       "<tr>\n",
       "      <td></td>      <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th> <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>3.7675</td>    <td>0.3466</td>   <td>10.869</td> <td>0.0000</td>   <td>3.0881</td>   <td>4.4468</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>       <td>0.1881</td>    <td>0.0261</td>   <td>7.1961</td> <td>0.0000</td>   <td>0.1368</td>   <td>0.2393</td> \n",
       "</tr>\n",
       "</table><br/><br/>Endogenous: educ<br/>Instruments: nearc4<br/>Robust Covariance (Heteroskedastic)<br/>Debiased: False"
      ],
      "text/plain": [
       "<class 'linearmodels.compat.statsmodels.Summary'>\n",
       "\"\"\"\n",
       "                          IV-2SLS Estimation Summary                          \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                     -0.5739\n",
       "Estimator:                    IV-2SLS   Adj. R-squared:                -0.5744\n",
       "No. Observations:                3010   F-statistic:                    51.784\n",
       "Date:                Tue, Mar 21 2023   P-value (F-stat)                0.0000\n",
       "Time:                        09:25:48   Distribution:                  chi2(1)\n",
       "Cov. Estimator:                robust                                         \n",
       "                                                                              \n",
       "                             Parameter Estimates                              \n",
       "==============================================================================\n",
       "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      3.7675     0.3466     10.869     0.0000      3.0881      4.4468\n",
       "educ           0.1881     0.0261     7.1961     0.0000      0.1368      0.2393\n",
       "==============================================================================\n",
       "\n",
       "Endogenous: educ\n",
       "Instruments: nearc4\n",
       "Robust Covariance (Heteroskedastic)\n",
       "Debiased: False\n",
       "\"\"\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_c4 = IV2SLS.from_formula(\"lwage ~ 1+[educ ~ nearc4 ]\", card).fit()\n",
    "iv_c4.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cdc97a",
   "metadata": {},
   "source": [
    "**Question 4.2 Use `IV2SLS.from_formula` to run the regression with log wages as the outcome, education as the treatment, and `nearc2` as the instrument (with the same control variables as above).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d2d7c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>IV-2SLS Estimation Summary</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>-1.2536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>-1.2581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>3003</td>       <th>  F-statistic:       </th> <td>296.29</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, Mar 20 2023</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:50:40</td>     <th>  Distribution:      </th> <td>chi2(6)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cov. Estimator:</th>        <td>robust</td>      <th>                     </th>    <td></td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td></td>         <th>                     </th>    <td></td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Parameter Estimates</caption>\n",
       "<tr>\n",
       "      <td></td>      <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th>  <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>0.2107</td>    <td>3.1235</td>   <td>0.0675</td>  <td>0.9462</td>   <td>-5.9112</td>  <td>6.3327</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>      <td>0.1051</td>    <td>0.1786</td>   <td>0.5888</td>  <td>0.5560</td>   <td>-0.2449</td>  <td>0.4552</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>      <td>0.1496</td>    <td>0.0744</td>   <td>2.0111</td>  <td>0.0443</td>   <td>0.0038</td>   <td>0.2954</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>    <td>-0.0149</td>   <td>0.0149</td>   <td>-0.9965</td> <td>0.3190</td>   <td>-0.0442</td>  <td>0.0144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smsa</th>       <td>0.0245</td>    <td>0.1018</td>   <td>0.2410</td>  <td>0.8095</td>   <td>-0.1749</td>  <td>0.2240</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>south</th>      <td>-0.0325</td>   <td>0.0689</td>   <td>-0.4719</td> <td>0.6370</td>   <td>-0.1675</td>  <td>0.1025</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>       <td>0.3566</td>    <td>0.1837</td>   <td>1.9410</td>  <td>0.0523</td>   <td>-0.0035</td>  <td>0.7167</td> \n",
       "</tr>\n",
       "</table><br/><br/>Endogenous: educ<br/>Instruments: nearc2<br/>Robust Covariance (Heteroskedastic)<br/>Debiased: False"
      ],
      "text/plain": [
       "<class 'linearmodels.compat.statsmodels.Summary'>\n",
       "\"\"\"\n",
       "                          IV-2SLS Estimation Summary                          \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                     -1.2536\n",
       "Estimator:                    IV-2SLS   Adj. R-squared:                -1.2581\n",
       "No. Observations:                3003   F-statistic:                    296.29\n",
       "Date:                Mon, Mar 20 2023   P-value (F-stat)                0.0000\n",
       "Time:                        10:50:40   Distribution:                  chi2(6)\n",
       "Cov. Estimator:                robust                                         \n",
       "                                                                              \n",
       "                             Parameter Estimates                              \n",
       "==============================================================================\n",
       "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.2107     3.1235     0.0675     0.9462     -5.9112      6.3327\n",
       "black          0.1051     0.1786     0.5888     0.5560     -0.2449      0.4552\n",
       "exper          0.1496     0.0744     2.0111     0.0443      0.0038      0.2954\n",
       "married       -0.0149     0.0149    -0.9965     0.3190     -0.0442      0.0144\n",
       "smsa           0.0245     0.1018     0.2410     0.8095     -0.1749      0.2240\n",
       "south         -0.0325     0.0689    -0.4719     0.6370     -0.1675      0.1025\n",
       "educ           0.3566     0.1837     1.9410     0.0523     -0.0035      0.7167\n",
       "==============================================================================\n",
       "\n",
       "Endogenous: educ\n",
       "Instruments: nearc2\n",
       "Robust Covariance (Heteroskedastic)\n",
       "Debiased: False\n",
       "\"\"\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2SLS\n",
    "iv_c2_mv = IV2SLS.from_formula(\"lwage ~ 1 + exper + black + south + married + smsa + [educ ~ nearc2 ]\", \n",
    "                               data=card).fit()\n",
    "iv_c2_mv.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d1c9bb",
   "metadata": {},
   "source": [
    "You should get a larger coefficient on `educ` in the regressions with `nearc2` as an instrument compared to `nearc4`. There are a few reasons this may be the case, but one possibility is that the \"compliers\" with the instruments are different. In other words, the kind of person induced to get more education by growing up near a two year college may be different than the kind of person induced to get more education by growing up near a four year college."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e65c037",
   "metadata": {},
   "source": [
    "**Question 4.3 [Optional] It is also possible that the exogeneity or exclusion restriction assumptions are not met here. Give a reason why these might not hold.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf5718",
   "metadata": {},
   "source": [
    "People who live near a 2 or 4 year college may also grow up with more educated people, who become a more useful professional network when they grow up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4bdd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
